{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Normalization and Filters\n\nIn this notebook, we'll explore image normalization and filters.\n\nLet's start by loading and visualizing an image."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import image as mp_image\n\n# Required magic to display matplotlib plots in notebooks\n%matplotlib inline\n\n# Load the image from the source file\nimage_file = \"../data/voc/automobile/000142.jpg\"\nimage = mp_image.imread(image_file)\n\n# Display it\nplt.imshow(image)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Image Normalization"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's look at the distribution of pixel values in the image. Ideally, the image should have relatively even distribution of values, indicating good contrast and making it easier to extract analytical information.\n\nAn easy way to check this is to plot a histogram."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Plot a histogram - we need to use ravel to \"flatten\" the 3 dimensions\nplt.hist(image.ravel())\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Another useful way to visualize the statistics of an image is as a cumulative distribution function (CDF) plot. Which shows the cumulative pixel intensity frequencies from 0 to 255."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "plt.hist(image.ravel(), bins=255, cumulative=True)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The histogram and CDF for our image show pretty uneven distribution - there's a lot of contrast in the image. Ideally we should equalize the values in the images we want to analyse to try to make our images more consistent in terms of the shapes they contain irrespective of light levels.\n\nOne simple way to do this is to apply a technique called *contrast stretching*, in which you rescale the pixel values to ensure that all values between a very low and very high percentile (usually the 2nd percentile and 98th percentile) are mapped to the range 0 to 255 - in effect \"stretching\" the histogram to try to ensure the distribution covers the full range of possible values.\n\n*Histogram equalization* is a more complex operation that creates a more uniform distribution. The code in the cell below uses the **exposure.rescale_intensity** and  **exposure.equalize_hist** methods from the **skimage** package to perform contrast stretching and histogram equalization."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from skimage import exposure\nimport numpy as np\n\n# Contrast stretching\np2 = np.percentile(image, 2)\np98 = np.percentile(image, 98)\nimage_ct = exposure.rescale_intensity(image, in_range=(p2, p98))\n\n# Histogram Equalization\nimage_eq = exposure.equalize_hist(image)\n\n# Show the images\nfig = plt.figure(figsize=(20, 12))\n\n# Subplot for original image\na=fig.add_subplot(3,3,1)\nimgplot = plt.imshow(image)\na.set_title('Original')\n\n# Subplot for contrast stretched image\na=fig.add_subplot(3,3,2)\nimgplot = plt.imshow(image_ct)\na.set_title('Contrast Stretched')\n\n# Subplot for equalized image\na=fig.add_subplot(3,3,3)\nimgplot = plt.imshow(image_eq)\na.set_title('Histogram Equalized')\n\n# Subplots for histograms\na=fig.add_subplot(3,3,4)\nimgplot = plt.hist(image.ravel())\n\na=fig.add_subplot(3,3,5)\nimgplot = plt.hist(image_ct.ravel())\n\na=fig.add_subplot(3,3,6)\nimgplot = plt.hist(image_eq.ravel())\n\n# Subplots for CDFs\n\na=fig.add_subplot(3,3,7)\nimgplot = plt.hist(image.ravel(), bins=255, cumulative=True)\n\na=fig.add_subplot(3,3,8)\nimgplot = plt.hist(image_ct.ravel(), bins=255, cumulative=True)\n\na=fig.add_subplot(3,3,9)\nimgplot = plt.hist(image_eq.ravel(), bins=255, cumulative=True)\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As you can see, contrast stretching results in a histogram of mroe or less the same shape, but spread out over the full range of pixel values. The CDF is slightly smoother than for the original image. Histogram equalization has produced a much more even distribution of pixel values, and a more or less perfectly diagonal CDF; but the image itself is noticable less natural looking.\n\nThese kind of contrast enhancements can be useful when images have low contrast. They're particularly useful in medical imaging scenarios, for example to enhance X-rays. They can also be used to counteract contrast variance in a set of images that will be used to train  amachine learning model."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Filters\n\nFilters are implemented by defining numeric grids, called *kernels* that are convolved across an image to change the value of the pixel in the middle of the grid by calculating a weighted sum of the surrounding pixels, using the values in the kernel as weights. In practice they are used to apply visual enhancement effects to the image; such as sharpening, blurring, and so on. This can often be used to remove \"noise\" from an image, such as is common in photgraphs taken in low-light conditions.\n\nLet's take a look at some common filters in the **PIL.ImageFilter** library:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageFilter\n\n# Required magic to display matplotlib plots in notebooks\n%matplotlib inline\n\n# Load the image from the source file\nimage_file = \"../data/voc/plane/002279.jpg\"\nimage = Image.open(image_file)\n\nblurred_image = image.filter(ImageFilter.BLUR)\nsharpened_image = image.filter(ImageFilter.SHARPEN)\n\n# Display it\nfig = plt.figure(figsize=(16, 12))\n\n# Plot original image\na=fig.add_subplot(1, 3, 1)\nimage_plot_1 = plt.imshow(image)\na.set_title(\"Original\")\n\n# Plot blurred image\na=fig.add_subplot(1, 3, 2)\nimage_plot_2 = plt.imshow(blurred_image)\na.set_title(\"Blurred\")\n\n# Plot sharpened image\na=fig.add_subplot(1, 3, 3)\nimage_plot_3 = plt.imshow(sharpened_image)\na.set_title(\"Sharpened\")\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Since a filter kernel is just a grid of numbers, you can create your own filters as numpy arrays, like this:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "my_kernel = (200, 50, -100,\n             -50, 200, -50,\n            -100, 50, 200)\n\nfiltered_image = image.filter(ImageFilter.Kernel((3,3), my_kernel))\n\n# Display it\nfig = plt.figure(figsize=(16, 12))\n\n# Plot original image\na=fig.add_subplot(1, 2, 1)\nimage_plot_1 = plt.imshow(image)\na.set_title(\"Original\")\n\n# Plot filtered image\na=fig.add_subplot(1, 2, 2)\nimage_plot_2 = plt.imshow(filtered_image)\na.set_title(\"Custom Filter\")\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Detecting Edges\n\nOne particular use of filters is to detect the edges of objects in an image. PIL includes a FIND_EDGES filter for this purpose:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageFilter\n\n# Required magic to display matplotlib plots in notebooks\n%matplotlib inline\n\n# Load the image from the source file\nimage_file = \"../data/voc/plane/002279.jpg\"\nimage = Image.open(image_file)\n\nedges_image = image.filter(ImageFilter.FIND_EDGES)\n\n# Display it\nfig = plt.figure(figsize=(16, 12))\n\n# Plot original image\na=fig.add_subplot(1, 2, 1)\nimage_plot_1 = plt.imshow(image)\na.set_title(\"Original\")\n\n# Plot filtered image\na=fig.add_subplot(1, 2, 2)\nimage_plot_2 = plt.imshow(edges_image)\na.set_title(\"Edges\")\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "If the built-in FIND-EDGES filter doesn't provide what you need, you could use a Sobel edge-detection algorithm; which involves convolving two filters across an image to find the horizontal and vertical vector gradients for each pixel, and then calculating the magnitude (length) of each vector gradient:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def edge_sobel(image):\n    from scipy import ndimage\n    import skimage.color as sc\n    import numpy as np\n    image = sc.rgb2gray(image) # Convert color image to gray scale\n    dx = ndimage.sobel(image, 1)  # horizontal derivative\n    dy = ndimage.sobel(image, 0)  # vertical derivative\n    mag = np.hypot(dx, dy)  # magnitude\n    mag *= 255.0 / np.amax(mag)  # normalize (Q&D)\n    mag = mag.astype(np.uint8)\n    return mag\n\nsobel_image = edge_sobel(np.array(image))\n\n# Display it\nfig = plt.figure(figsize=(16, 12))\n\n# Plot original image\na=fig.add_subplot(1, 3, 1)\nimage_plot_1 = plt.imshow(image)\na.set_title(\"Original\")\n\n# Plot PIL FIND_EDGES image\na=fig.add_subplot(1, 3, 2)\nimage_plot_2 = plt.imshow(edges_image)\na.set_title(\"Edges\")\n\n# Plot Sobel image\na=fig.add_subplot(1, 3, 3)\nimage_plot_2 = plt.imshow(sobel_image, cmap=\"gray\") # Need to use a gray color map as we converted this to a grayscale image\na.set_title(\"Sobel\")\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Acknowledgements and Citations\n\nThe data used in this exercise includes images adapted from the PASCAL Visual Object Classes Challenge (VOC2007) dataset at http://host.robots.ox.ac.uk/pascal/VOC/voc2007/.\n\n\n    @misc{pascal-voc-2007,\n        author = \"Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.\",\n        title = \"The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2007 {(VOC2007)} {R}esults\",\n        howpublished = \"http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html\"}"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}