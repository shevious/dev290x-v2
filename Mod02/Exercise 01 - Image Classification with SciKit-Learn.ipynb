{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Image Classification with SciKit-Learn\n\nIn this notebook, we'll explore some basic principles for building a classifier for images. Our classifier will be pretty simple, and will differentiate between circles, triangles, and squares."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def prep_data (folder):\n    # iterate through folders, assembling feature, label, and classname data objects\n    import os\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    class_id = 0\n    features = []\n    labels = np.array([])\n    classnames = []\n    for root, dirs, filenames in os.walk(folder):\n        for d in sorted(dirs):\n            print(\"Reading data from\", d)\n            # use the folder name as the class name for this label\n            classnames.append(d)\n            files = os.listdir(os.path.join(root,d))\n            for f in files:\n                # Load the image file\n                imgFile = os.path.join(root,d, f)\n                img = plt.imread(imgFile)\n                # The image array is a multidimensional numpy array\n                # - flatten it to a single array of pixel values for scikit-learn\n                # - and add it to the list of features\n                features.append(img.ravel())\n                \n                # Add it to the numpy array of labels\n                labels = np.append(labels, class_id )\n            class_id  += 1\n            \n    # Convert the list of features into a numpy array\n    features = np.array(features)\n    \n    return features, labels, classnames\n\n\n# The images are in a folder named 'shapes/training'\ntraining_folder_name = '../data/shapes/training'\n\n# Prepare the image data\nfeatures, labels, classnames = prep_data(training_folder_name)\nprint(len(features), 'features')\nprint(len(labels), 'labels')\nprint(len(classnames), 'classes:', classnames)",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Reading data from circle\nReading data from square\nReading data from triangle\n1200 features\n1200 labels\n3 classes: ['circle', 'square', 'triangle']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's verify the shapes of the arrays -  we should have a two-dimensional array of features (each image is itself an array), and one dimensional array of labels (each label is an integer value)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print('Feature Shape:',features.shape)\nprint('Labels Shape:',labels.shape)",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Feature Shape: (1200, 49152)\nLabels Shape: (1200,)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Split the data\nNow that the image data is prepared, we can split it into training (70%) and test (30%) subsets:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# split into training and testing sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.30)\n\nprint('Training records:',Y_train.size)\nprint('Test records:',Y_test.size)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Training records: 840\nTest records: 360\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Train the classification model\n\nNow we'll use the prepared image data to train a model.\n\nIn this case, we'll define a pipeline that contains two steps:\n1. Normalize the pixel values so that they are scaled between 0 and 1 - this can prevent high pixel density values from dominating the model training.\n2. Train the model using a *Decision Tree* algorithm for classification (this is one of many algorithms supported by Scikit-Learn - see the [documentation](https://scikit-learn.org/stable/user_guide.html) for details)\n\n*(This may take a few minutes)*"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Train the model\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Convert the training features to floats so they can be scaled\nX_train_float = X_train.astype('float64')\n\n# Our pipeline performs two tasks:\n#   1. Normalize the image arrays\n#   2. Train a classification model\nimg_pipeline = Pipeline([('norm', MinMaxScaler()),\n                         ('classify', DecisionTreeClassifier()),\n                        ])\n\n# Use the pipeline to fit a model to the training data\nprint(\"Training model...\")\nclf = img_pipeline.fit(X_train_float, Y_train)\n\nprint('classifier trained!')",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Training model...\nclassifier trained!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Evaluate the model\nWith our model trained, we'll use it to predict labels for the test data and evaluate its precision, recall, and simple accuracy using the known labels. Then we'll plot the confusion matrix to evaluate how well the model performs for each class label."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Evaluate classifier\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Convert the test features for scaling\nX_test_float = X_test.astype('float64')\n\nprint('Classifier Metrics:')\npredictions = clf.predict(X_test)\nprint(metrics.classification_report(Y_test, predictions, target_names=classnames))\nprint('Accuracy: {:.2%}'.format(metrics.accuracy_score(Y_test, predictions)))\n\nprint(\"\\n Confusion Matrix:\")\ncm = confusion_matrix(Y_test, np.round(predictions, 0))\n# Plot confusion matrix as heatmap\nplt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\nplt.colorbar()\ntick_marks = np.arange(len(classnames))\nplt.xticks(tick_marks, classnames, rotation=85)\nplt.yticks(tick_marks, classnames)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Save the Model\nNow that we have trained the model, we can save it, and use it later to predict classes from new images."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Save the trained model\nimport sys\nimport os\nimport pickle\n\nprint (\"Exporting the model\")\nfile_stream = open('shape_classifier.pkl', 'wb')\npickle.dump(clf, file_stream)\nfile_stream.close()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Use the model with new data\nNow we can use the model to classify new images.\n\n### Create Functions to Prepare Data and Get Class Predictions\nLet's create a couple of functions to:\n\n- Resize new images to match the size on which the model was trained.\n- Submit the new images to the model and retrieve the predicted classes."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Helper function to resize image\ndef resize_image(src_img, size=(128,128), bg_color=\"white\"): \n    from PIL import Image\n\n    # rescale the image so the longest edge is the right size\n    src_img.thumbnail(size, Image.ANTIALIAS)\n    \n    # Create a new image of the right shape\n    new_image = Image.new(\"RGB\", size, bg_color)\n    \n    # Paste the rescaled image onto the new background\n    new_image.paste(src_img, (int((size[0] - src_img.size[0]) / 2), int((size[1] - src_img.size[1]) / 2)))\n  \n    # return the resized image\n    return new_image\n\n# Function to predict the class of an image\ndef predict_image(classifier, image_array):\n    import numpy as np\n    \n    # These are the classes our model can predict\n    classnames = ['circle', 'square', 'triangle']\n    \n    # Predict the class of each input image\n    predictions = classifier.predict(image_array)\n    \n    predicted_classes = []\n    for prediction in predictions:\n        # And append the corresponding class name to the results\n        predicted_classes.append(classnames[int(prediction)])\n    # Return the predictions\n    return predicted_classes\n\nprint(\"Functions created - ready to use model for inference.\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Predict Image Classes\nNow we're ready to use the model for predicting (often referred to as *inferencing*) the classes of some new images."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport numpy as np\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\n# Load the model\nprint(\"Importing the model\")\nfile_stream = open('shape_classifier.pkl', 'rb')\nclf = pickle.load(file_stream)\nfile_stream.close()\n\n#get the list of test image files\ntest_folder = '../data/shapes/test'\ntest_image_files = os.listdir(test_folder)\n\n# Empty array on which to store the images\nimage_arrays = []\n\nsize = (128,128)\nbackground_color = \"white\"\n\nfig = plt.figure(figsize=(12, 8))\n\n# Get the images and show the predicted classes\nfor file_idx in range(len(test_image_files)):\n    img = Image.open(os.path.join(test_folder, test_image_files[file_idx]))\n    \n    # resize the image so it matches the training set - it  must be the same size as the images on which the model was trained\n    resized_img = np.array(resize_image(img, size, background_color))\n    \n    img_shape = np.array(resized_img).shape\n                      \n    # Add the image to the array of images\n    image_arrays.append(resized_img.ravel())\n\n# Get predictions from the array of image arrays\n# Note that the model expects an array of 1 or more images - just like the batches on which it was trained\npredictions = predict_image(clf, np.array(image_arrays))\n\n# plot easch image with its corresponding prediction\nfor idx in range(len(predictions)):\n    a=fig.add_subplot(1,len(predictions),idx+1)\n    img = image_arrays[idx].reshape(img_shape)\n    imgplot = plt.imshow(img)\n    a.set_title(predictions[idx])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Learn More about Scikit-Learn\nTake a look at the [Scikit-Learn documentation](https://scikit-learn.org/stable/documentation.html)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}